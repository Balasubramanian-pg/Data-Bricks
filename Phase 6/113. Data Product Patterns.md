# 113. Data Product Patterns

Canonical documentation for [113. Data Product Patterns](Phase 6/113. Data Product Patterns.md). This document defines concepts, terminology, and standard usage.

## Purpose
The concept of Data Product Patterns addresses the systemic failure of centralized data architectures to scale with organizational complexity. As organizations transition from monolithic data lakes and warehouses toward decentralized models (such as Data Mesh), there is a critical need for standardized templates that define how data is packaged, shared, and maintained.

This topic exists to provide a framework for "Product Thinking" applied to data. It ensures that data assets are not merely byproducts of application code but are intentional, high-quality, and self-describing units of value that can be independently consumed by diverse stakeholders.

> [!NOTE]
> This documentation is intended to be implementation-agnostic and authoritative, focusing on the architectural and organizational logic rather than specific software tooling.

## Scope
Clarify what is in scope and out of scope for this topic.

> [!IMPORTANT]
> **In scope:**
> * Architectural archetypes for data product construction.
> * Structural patterns for input and output ports.
> * Lifecycle management and governance patterns.
> * Interoperability standards between heterogeneous data products.

> [!WARNING]
> **Out of scope:**
> * Specific vendor implementations (e.g., specific SQL dialects or cloud provider services).
> * General data engineering tutorials (e.g., how to write a Python ETL script).
> * Physical storage optimization techniques.

## Definitions
| Term | Definition |
|------|------------|
| Data Product | A logical unit that contains all components necessary to provide a specific data-driven value proposition, including code, data, metadata, and infrastructure. |
| Input Port | The mechanism through which a data product receives data from upstream sources or other data products. |
| Output Port | The standardized interface (API, Stream, Table) through which consumers access the data product's value. |
| Control Plane | The administrative layer responsible for governance, access control, and lifecycle management of the data product. |
| Polyglot Serving | The ability of a single data product to provide the same underlying data through multiple output formats (e.g., Parquet for batch, Avro for streams). |
| Sidecar | A utility component attached to a data product to handle cross-cutting concerns like logging, security, or metadata registration. |

## Core Concepts
The fundamental idea behind Data Product Patterns is the encapsulation of data within a "bounded context." Instead of data flowing into a giant, unmanaged pool, it is organized into discrete units that are owned by the domain experts who understand the data best.

### The Product Thinking Analogy
> [!TIP]
> Think of a Data Product like a modern smartphone application. The user doesn't need to know how the database is structured or what language the backend uses; they interact with a clean interface (the Output Port), rely on a consistent experience (SLOs), and expect the product to be discoverable in a store (the Data Catalog).

### Key Pillars
1.  **Autonomy:** Each data product should be deployable and manageable independently of others.
2.  **Interoperability:** Products must use global standards (e.g., common ID formats, standardized timestamps) to allow for cross-domain joining.
3.  **Discoverability:** A data product must be self-describing, providing enough metadata for a user to find and understand it without manual intervention.
4.  **Trustworthiness:** Every product must expose Service Level Objectives (SLOs) regarding its quality, freshness, and availability.

## Standard Model
The standard model for a Data Product is often visualized as a "hexagonal" or "containerized" architecture consisting of three primary planes:

1.  **The Data Plane:** Contains the actual data (storage) and the transformation logic (compute) that turns raw input into refined output.
2.  **The Control Plane:** Manages the "meta" aspectsâ€”access requests, policy enforcement, and registration with the central catalog.
3.  **The Utility Plane:** Provides the underlying infrastructure (storage buckets, compute clusters) required for the product to function.

## Common Patterns

### 1. Source-Aligned Pattern
This pattern focuses on capturing data directly from operational systems. The data product mirrors the structure of the source system but cleanses and translates it into a format suitable for analytical consumption.
*   **Primary Goal:** High fidelity to the source.
*   **Consumer:** Other data products (Aggregate or Consumer-aligned).

### 2. Aggregate Pattern
This pattern consumes data from multiple source-aligned data products to create a unified view of a specific business entity (e.g., "Customer 360").
*   **Primary Goal:** Cross-domain integration.
*   **Complexity:** High, due to the need for entity resolution and schema mapping.

### 3. Consumer-Aligned Pattern
Designed for a specific use case, such as a machine learning model or a specific executive dashboard. These products are highly transformed and optimized for read-heavy performance.
*   **Primary Goal:** Minimizing latency and maximizing relevance for the end-user.

### 4. The Streaming/Event Pattern
Instead of static tables, this pattern exposes data as a continuous stream of events.
*   **Primary Goal:** Real-time reactivity.
*   **Output Port:** Message queues or event logs.

## Anti-Patterns
Recognizing these common mistakes is vital for maintaining a healthy data ecosystem.

*   **The Data Dump:** Providing raw, undocumented files without any SLOs or ownership. This is a "byproduct," not a "product."
*   **The Monolithic Product:** Attempting to create a single data product that covers an entire enterprise. This leads to the same scaling bottlenecks as a centralized data warehouse.
*   **The Black Box:** A data product that provides output but hides its lineage, quality metrics, and transformation logic, making it impossible for consumers to trust the data.
*   **Circular Dependencies:** Data Product A depends on B, which depends on C, which depends on A. This creates a fragile ecosystem where a single failure cascades.

> [!CAUTION]
> Avoid tight coupling between data products. If a change in the internal schema of Product A breaks Product B, the "Output Port" abstraction has failed. Always version your output ports.

## Edge Cases
*   **Legacy Systems:** Systems that cannot support modern input/output ports (e.g., mainframes). These require "Adapter" data products to bridge the gap.
*   **Highly Regulated Data:** Data products containing PII (Personally Identifiable Information) that must dynamically mask data based on the consumer's identity.
*   **Transient Data Products:** Short-lived products created for a specific experiment or a one-time audit. These must still follow minimal governance patterns to avoid "data debt."

## Related Topics
*   **101. Data Mesh Principles:** The foundational philosophy for decentralized data.
*   **105. Data Governance Frameworks:** The policies enforced by the Control Plane.
*   **110. Schema Evolution and Versioning:** Critical for maintaining stable Output Ports.
*   **120. Federated Computational Governance:** How global policies are applied to local data products.

## Change Log
| Version | Date | Description |
|---------|------|-------------|
| 1.0 | 2026-01-26 | Initial AI-generated canonical documentation |