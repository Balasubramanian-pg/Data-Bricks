# 120. Lambda Architecture on Databricks

Canonical documentation for [120. Lambda Architecture on Databricks](Phase 6/120. Lambda Architecture on Databricks.md). This document defines concepts, terminology, and standard usage.

## Purpose
The Lambda Architecture on Databricks addresses the fundamental challenge of balancing latency, throughput, and fault tolerance in large-scale data processing. It provides a robust framework for processing massive quantities of data by utilizing both batch and stream-processing methods. This dual-path approach ensures that users have access to low-latency views of recent data (Speed Layer) while maintaining a comprehensive, accurate, and recomputable historical record (Batch Layer).

> [!NOTE]
> This documentation is intended to be implementation-agnostic regarding specific coding languages (Scala vs. Python) and authoritative regarding the architectural design within the Databricks ecosystem.

## Scope
This documentation covers the theoretical and structural application of the Lambda Architecture within a unified data analytics platform.

> [!IMPORTANT]
> **In scope:**
> * Structural components: Batch Layer, Speed Layer, and Serving Layer.
> * Data flow mechanics between immutable master datasets and real-time increments.
> * Theoretical boundaries of consistency and latency trade-offs.
> * Integration of unified storage (Delta Lake) as the foundation for both paths.

> [!WARNING]
> **Out of scope:**
> * Specific vendor implementations outside of the Databricks/Spark ecosystem.
> * Step-by-step coding tutorials or API-specific syntax.
> * Comparison with non-distributed database architectures.

## Definitions
| Term | Definition |
|------|------------|
| Batch Layer | The component responsible for managing the master dataset (immutable, append-only) and pre-computing the batch views. |
| Speed Layer | The component that processes data in real-time to provide low-latency views, compensating for the high latency of the batch layer. |
| Serving Layer | The output layer that responds to ad-hoc queries by merging results from both batch and speed views. |
| Master Dataset | The source of truth containing the raw, immutable data collected over the entire history of the system. |
| Recomputation | The process of re-running the batch layer logic over the master dataset to correct errors or update logic. |
| Delta Lake | An open-source storage layer that brings ACID transactions to Apache Spark and big data workloads, often serving as the physical storage for Lambda layers. |

## Core Concepts
The Lambda Architecture is built on the principle that data is immutable and that any view of the data is a function of all previous data.

1.  **Immutability:** Data is never overwritten; it is only appended. This ensures that the master dataset remains a permanent record of events.
2.  **Recomputation:** Because the batch layer processes the entire master dataset, any logic errors can be fixed by simply re-running the batch process.
3.  **Complexity Management:** By separating the concerns of "real-time" and "historical accuracy," the architecture allows for different technologies or configurations to be optimized for specific goals (speed vs. completeness).

> [!TIP]
> Think of Lambda Architecture like a bank ledger. The Batch Layer is the monthly statement (highly accurate, verified, but slow), while the Speed Layer is the "pending transactions" list on your mobile app (immediate, but subject to change or correction).

## Standard Model
The standard model for Lambda Architecture on Databricks utilizes a unified engine (Apache Spark) to handle both processing paths, typically backed by Delta Lake.

*   **The Batch Path:** Data is ingested into a "Bronze" or raw Delta table. Periodically, a batch job processes this data into "Silver" (cleansed) and "Gold" (aggregated) tables. This path provides the "Source of Truth."
*   **The Speed Path:** Using Structured Streaming, data is processed as it arrives. This path bypasses the heavy transformations of the batch layer to provide immediate insights, often stored in a high-speed cache or a volatile Delta table.
*   **The Serving Path:** A query layer (such as Databricks SQL or a specialized BI connector) joins the results from the Batch Gold tables and the Speed Layer views to provide a unified, up-to-date response to the end user.

## Common Patterns
*   **Unified Storage Pattern:** Using Delta Lake as the sink for both the Batch and Speed layers. This simplifies the architecture by allowing the Serving Layer to query a single storage format.
*   **Incremental Batching:** Using the `trigger(availableNow=true)` mechanism in Spark to simulate batch processing using streaming logic, reducing the code divergence between the two layers.
*   **Drop-and-Replace Speed Layer:** Periodically purging the Speed Layer once the Batch Layer has "caught up" and incorporated those time intervals into the master dataset.

## Anti-Patterns
*   **Logic Divergence:** Maintaining two entirely different codebases for the Batch and Speed layers. This leads to "impedance mismatch" where the two layers produce slightly different results for the same data.
*   **Over-Engineering:** Implementing Lambda when a "Kappa Architecture" (streaming only) or a simple Medallion Architecture (batch-only or stream-only) would suffice.
*   **Ignoring Idempotency:** Failing to ensure that re-running the batch layer produces the exact same results, leading to corrupted historical views.

> [!CAUTION]
> Avoid circular dependencies where the Speed Layer depends on the output of the Batch Layer to function, as this defeats the purpose of the independent low-latency path.

## Edge Cases
*   **Late-Arriving Data:** Data that arrives after the Batch Layer has already processed its window. The architecture must be designed to either update the batch view or handle the discrepancy in the Serving Layer.
*   **Schema Evolution:** When the structure of the incoming data changes, both the Speed and Batch layers must be updated simultaneously to prevent the Serving Layer from failing during the merge of views.
*   **Historical Restatements:** When business logic changes retroactively, the Batch Layer must reprocess years of data, which can temporarily increase the load on the Databricks cluster and impact the Serving Layer's performance.

## Related Topics
*   **Kappa Architecture:** A simplification of Lambda that removes the batch layer, treating all data as a stream.
*   **Medallion Architecture:** The Databricks-specific data design pattern (Bronze/Silver/Gold) often used to implement the layers of Lambda.
*   **Structured Streaming:** The underlying engine used for the Speed Layer on Databricks.
*   **Delta Lake:** The storage framework that provides the ACID guarantees necessary for the Serving Layer.

## Change Log
| Version | Date | Description |
|---------|------|-------------|
| 1.0 | 2026-01-26 | Initial AI-generated canonical documentation |