# 110. Adaptive Query Execution at Scale

Canonical documentation for [110. Adaptive Query Execution at Scale](Phase 6/110. Adaptive Query Execution at Scale.md). This document defines concepts, terminology, and standard usage.

## Purpose
Adaptive Query Execution (AQE) addresses the inherent limitations of static query optimization in distributed computing environments. In large-scale data processing, traditional optimizers rely on pre-execution statistics (e.g., cardinality, histograms) to generate an execution plan. However, these statistics are often stale, inaccurate, or non-existent for intermediate results in complex pipelines.

AQE enables a query engine to re-optimize and adjust the execution plan dynamically at runtime based on actual data characteristics observed during the execution process. This minimizes resource wastage, reduces execution latency, and increases the robustness of data pipelines against data skew and fluctuating data volumes.

> [!NOTE]
> This documentation is intended to be implementation-agnostic and authoritative, focusing on the architectural patterns common to high-performance distributed SQL engines.

## Scope
Clarify what is in scope and out of scope for this topic.

> [!IMPORTANT]
> **In scope:**
> * Runtime re-optimization of physical execution plans.
> * Dynamic adjustment of join strategies and parallelism.
> * Automated handling of data skew at scale.
> * Feedback loops between execution stages and the optimizer.

> [!WARNING]
> **Out of scope:**
> * Specific vendor-specific configuration parameters (e.g., Spark, Trino, or Snowflake-specific flags).
> * Static Cost-Based Optimization (CBO) performed entirely before execution begins.
> * Hardware-level optimizations (e.g., SIMD, GPU acceleration).

## Definitions
Provide precise definitions for key terms.

| Term | Definition |
|------|------------|
| Query Stage | A segment of a query plan that can be executed independently until a data redistribution (shuffle) point is reached. |
| Materialization Point | A boundary in the execution graph where data is written to disk or memory, allowing the engine to collect statistics before proceeding. |
| Shuffle | The process of redistributing data across a cluster, typically the most expensive operation in distributed queries. |
| Data Skew | A condition where a disproportionately large amount of data is concentrated in a small number of partitions. |
| Partition Coalescing | The process of merging small, fragmented data partitions into larger, more efficient units during runtime. |
| Join Promotion | Dynamically switching from a heavy join strategy (e.g., Sort-Merge) to a lighter one (e.g., Broadcast) based on actual intermediate data size. |

## Core Concepts
The fundamental premise of AQE is that "the best time to optimize a query is when you have the data in hand."

### The Feedback Loop
AQE transforms the linear "Plan -> Execute" model into a cyclical "Plan -> Execute Stage -> Observe -> Re-plan" model. By breaking a query into independent stages separated by shuffle boundaries, the engine treats the output of one stage as the ground-truth input for the next.

### Runtime Statistics Collection
As a stage completes, the engine aggregates metadata such as:
* Exact row counts.
* Actual byte sizes of partitions.
* Distribution of keys (identifying skew).

> [!TIP]
> Think of AQE like a GPS navigation system. A static optimizer picks a route before you leave the driveway based on historical averages. AQE is the "real-time rerouting" that detects a traffic jam (data skew) or a closed road (empty partition) and adjusts your path while you are already driving.

## Standard Model
The standard model for AQE at scale involves three primary pillars of optimization:

### 1. Dynamic Partition Coalescing
In distributed joins or aggregations, the number of partitions is often set to a high default to handle worst-case scenarios. This leads to "small file problems" and excessive scheduling overhead. AQE monitors the size of shuffle files and automatically merges small partitions into larger ones to ensure each task processes an optimal amount of data.

### 2. Dynamic Join Selection
Static optimizers often choose Sort-Merge Joins because they cannot guarantee that one side of a join will fit in memory. AQE observes the actual size of the relation after filtering and, if it falls below a threshold, converts the join to a Broadcast Hash Join, eliminating the need for expensive sorting and shuffling.

### 3. Skew Join Optimization
Data skew causes "straggler" tasks that bottleneck the entire query. The standard model for AQE detects skewed partitions (e.g., those significantly larger than the median) and splits them into smaller sub-partitions. These sub-partitions are then joined in parallel with the corresponding data from the other side of the join, balancing the load across the cluster.

## Common Patterns
* **Post-Shuffle Re-partitioning:** Adjusting the number of reducers based on the volume of data actually shuffled.
* **Empty Relation Propagation:** If a filter stage results in zero rows, AQE can prune subsequent stages of the query plan entirely, preventing unnecessary resource allocation.
* **Local Join Optimization:** Preferring collocated data processing when AQE detects that data is already partitioned by the join key.

## Anti-Patterns
* **Over-Instrumentation:** Collecting excessively granular statistics (e.g., full histograms for every column) during execution, where the overhead of collection exceeds the time saved by optimization.
* **Aggressive Coalescing:** Merging partitions so aggressively that the resulting tasks exceed the memory limits of the executors, leading to "Out of Memory" (OOM) errors.
* **Static Threshold Reliance:** Using hard-coded byte thresholds for join promotion that do not account for the available memory of the specific cluster nodes.

> [!CAUTION]
> Avoid circular dependencies where the re-optimization logic triggers a re-shuffle of data that was just shuffled, as this can lead to infinite execution loops or "shuffle storms."

## Edge Cases
* **Zero-Row Stages:** When a stage returns no data, the optimizer must be careful not to break downstream schemas or metadata expectations while skipping execution.
* **Highly Volatile UDFs:** User-Defined Functions that produce unpredictable data volumes can confuse AQE if the engine cannot estimate the growth factor of the data.
* **Broadcast Limits:** In Join Promotion, if the "small" side of the join is slightly larger than the broadcast threshold but is promoted anyway, it can crash the driver or orchestrator node.
* **Streaming-Batch Hybrids:** AQE is significantly more complex in continuous processing (streaming) because there are no clear "materialization points" to pause and re-plan.

## Related Topics
* **Cost-Based Optimization (CBO):** The static precursor to AQE.
* **Vectorized Execution:** A complementary technique for increasing per-node processing speed.
* **Data Shuffling and Partitioning:** The underlying mechanism that AQE seeks to optimize.
* **Resource Management (YARN/Kubernetes):** The layer that provides the compute resources AQE manages.

## Change Log
| Version | Date | Description |
|---------|------|-------------|
| 1.0 | 2026-01-26 | Initial AI-generated canonical documentation |