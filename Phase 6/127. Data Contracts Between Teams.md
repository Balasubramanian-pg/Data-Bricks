# 127. Data Contracts Between Teams

Canonical documentation for [127. Data Contracts Between Teams](Phase 6/127. Data Contracts Between Teams.md). This document defines concepts, terminology, and standard usage.

## Purpose
Data Contracts exist to resolve the inherent friction between data producers (who generate data via operational systems) and data consumers (who utilize data for analytics, machine learning, and decision-making). In distributed architectures, changes in upstream source systems often cause silent failures downstream. 

This topic addresses the "broken pipeline" problem by formalizing the interface between teams. It shifts the paradigm from data being a byproduct of software development to data being a deliberate, versioned product. By establishing a formal agreement, organizations can ensure data quality, reliability, and long-term maintainability of data-driven applications.

> [!NOTE]
> This documentation is intended to be implementation-agnostic and authoritative, focusing on the architectural and organizational requirements of data contracts rather than specific software tools.

## Scope
Clarify what is in scope and out of scope for this topic.

> [!IMPORTANT]
> **In scope:**
> * The structural definition of data (schemas).
> * The semantic meaning of data fields.
> * Quality guarantees and Service Level Agreements (SLAs).
> * Governance and ownership models.
> * Evolution and versioning strategies for data interfaces.

> [!WARNING]
> **Out of scope:**
> * Specific vendor implementations (e.g., specific features of Confluent, dbt, or Soda).
> * Physical storage optimization (e.g., partitioning strategies, file formats like Parquet vs. Avro).
> * General data engineering pipeline construction.

## Definitions
Provide precise definitions for key terms.

| Term | Definition |
|------|------------|
| Data Contract | A formal agreement between a producer and a consumer that defines the structure, semantics, and quality of data exchanged. |
| Producer | The team or service responsible for generating and providing the data. |
| Consumer | The team or service that ingests and utilizes the data for downstream purposes. |
| Schema | The technical specification of data fields, types, and constraints. |
| Semantic Versioning | A versioning scheme (Major.Minor.Patch) used to communicate the nature of changes in a contract. |
| Data Quality SLA | Defined metrics (e.g., freshness, completeness, accuracy) that the producer guarantees to the consumer. |
| Breaking Change | A modification to the contract that requires consumers to update their logic to avoid failure. |

## Core Concepts
The fundamental idea behind a Data Contract is to treat data as an API. Just as microservices communicate via stable REST or gRPC interfaces, data teams should communicate via stable data interfaces.

**1. Ownership and Accountability**
Data contracts shift the responsibility of data quality to the source. The producer is accountable for ensuring the data emitted meets the agreed-upon standards, rather than the consumer "cleaning" the data after the fact.

**2. Decoupling**
Contracts decouple the internal implementation of a source system from the data it exposes. This allows producers to refactor their internal databases without breaking downstream analytical pipelines, provided the contract remains fulfilled.

**3. Enforcement**
A contract is only effective if it is enforced. This typically involves automated validation at the point of ingestion or emission to ensure data conforms to the schema and quality rules.

> [!TIP]
> Think of a Data Contract as a legal lease for an apartment. The "Schema" is the floor plan; the "SLA" is the guarantee of running water and electricity; and the "Versioning" is the process for renewing or changing the terms of the lease.

## Standard Model
The standard model for a Data Contract consists of four primary layers:

1.  **The Interface Layer:** Defines the technical schema (field names, data types, nullability) and the transport mechanism (e.g., event stream, batch table).
2.  **The Semantic Layer:** Defines the business meaning of the data. It ensures that a field named `status_id` means the same thing to both the producer and the consumer.
3.  **The Quality Layer:** Defines the constraints and expectations, such as "this field must never be empty" or "values must fall between 0 and 100."
4.  **The Metadata Layer:** Includes administrative information such as ownership, contact details, deprecation dates, and security classifications (e.g., PII status).

## Common Patterns

**Contract-First Development**
In this pattern, the contract is written and agreed upon *before* any data pipeline or service code is developed. This ensures that both teams are aligned on requirements from the outset.

**The Registry Pattern**
Contracts are stored in a centralized, version-controlled repository (a Schema Registry or Contract Catalog). This serves as the single source of truth for all inter-team data exchanges.

**Push-Based Validation**
The producer validates data against the contract before it is published. If the data fails validation, it is rejected at the source, preventing "garbage" from entering the data ecosystem.

## Anti-Patterns

**The "Throw it Over the Wall" Approach**
Producers dump raw database mirrors into a data lake without documentation or guarantees, leaving consumers to reverse-engineer the meaning and quality of the data.

**Schema-Only Contracts**
Relying solely on technical types (e.g., "this is a string") without defining the semantic meaning or quality expectations. A valid string can still contain invalid data.

**Circular Dependencies**
Creating contracts where Team A depends on Team B, which in turn depends on Team A’s output to fulfill its own contract.

> [!CAUTION]
> Avoid tight coupling where the data contract is a direct mirror of an internal production database schema. This creates "Change Fragility," where every internal change becomes a public breaking change.

## Edge Cases

**Late-Arriving Data**
In streaming architectures, data may arrive out of order or after a defined SLA window. Contracts must specify how late-arriving data is handled—whether it is discarded, updated, or processed in a separate flow.

**Schema Evolution (Non-Breaking)**
Adding a new optional field is generally considered non-breaking. However, in some strict consumer implementations, even adding a field can cause issues. The contract should define the "evolution policy" (e.g., Forward, Backward, or Full compatibility).

**PII and Compliance**
When a contract involves sensitive data, the contract must define the hashing, masking, or encryption requirements. A change in the encryption method is a breaking change even if the schema remains identical.

## Related Topics
*   **Data Mesh:** An architectural framework where data contracts are the primary mechanism for connecting decentralized data domains.
*   **Data Governance:** The overarching strategy for managing data assets, of which contracts are a tactical implementation.
*   **Observability:** The monitoring of data pipelines to ensure contracts are being honored in real-time.
*   **API Management:** The discipline of managing software interfaces, which shares many lifecycle principles with data contracts.

## Change Log

| Version | Date | Description |
|---------|------|-------------|
| 1.0 | 2026-01-26 | Initial AI-generated canonical documentation |