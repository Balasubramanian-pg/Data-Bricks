# 101. Warehouse Sizing for Performance

Canonical documentation for [101. Warehouse Sizing for Performance](Phase 6/101. Warehouse Sizing for Performance.md). This document defines concepts, terminology, and standard usage.

## Purpose
The purpose of warehouse sizing is to align computational resources with the specific demands of data workloads to achieve an optimal balance between execution speed (latency), volume of work (throughput), and resource expenditure. In modern data architecture, sizing addresses the decoupling of storage and compute, allowing for the independent scaling of processing power to meet fluctuating analytical demands.

> [!NOTE]
> This documentation is intended to be implementation-agnostic and authoritative, focusing on the universal principles of distributed compute allocation.

## Scope
Clarify what is in scope and out of scope for this topic.

> [!IMPORTANT]
> **In scope:**
> * Mechanics of vertical and horizontal scaling.
> * Relationship between data volume, query complexity, and compute requirements.
> * Strategies for workload isolation and concurrency management.
> * Performance metrics and benchmarking principles.

> [!WARNING]
> **Out of scope:**
> * Specific vendor pricing tiers or credit-to-currency conversions.
> * Physical hardware procurement or data center cooling.
> * Database indexing strategies (which are distinct from compute sizing).

## Definitions
Provide precise definitions for key terms.

| Term | Definition |
|------|------------|
| Compute Cluster | A logical grouping of CPU, memory, and local storage resources used to execute queries. |
| Vertical Scaling | Increasing the power (CPU/RAM) of a single compute cluster to handle larger or more complex individual tasks. |
| Horizontal Scaling | Increasing the number of clusters to handle a higher volume of concurrent tasks. |
| Throughput | The total number of queries or tasks completed within a specific time window. |
| Latency | The duration of time required to complete a single, specific query or task. |
| Concurrency | The number of queries or tasks being executed simultaneously by the system. |
| Spill to Disk | A performance degradation state where compute memory is exhausted, forcing the system to use slower local or remote storage for intermediate processing. |

## Core Concepts
The fundamental principle of warehouse sizing is the "Right-Sizing" equilibrium. Unlike traditional fixed-capacity systems, modern warehouses allow for elastic resource allocation.

**The Relationship of Scale**
Performance in a distributed warehouse is generally governed by the ability to parallelize tasks. If a dataset is partitioned effectively, doubling the compute resources (vertical scaling) should, in an ideal scenario, halve the execution time for a single complex query.

**Workload Categorization**
Not all workloads benefit from the same sizing strategy:
*   **Large, Complex Queries:** Benefit from vertical scaling (larger clusters) to provide more memory and parallel processing power for massive joins and aggregations.
*   **High-Volume, Simple Queries:** Benefit from horizontal scaling (more clusters) to prevent queuing and manage high concurrency.

> [!TIP]
> Think of warehouse sizing like a professional kitchen. Vertical scaling is like buying a larger, faster stove to cook a massive pot of stew more quickly. Horizontal scaling is like adding more stoves and more chefs to handle 50 individual orders of eggs at the same time.

## Standard Model
The standard model for warehouse sizing follows an iterative lifecycle:

1.  **Baseline Establishment:** Start with a medium-sized allocation based on estimated data volume and query complexity.
2.  **Monitoring:** Observe key performance indicators (KPIs) such as execution time, queue time, and memory usage (spillage).
3.  **Optimization:** 
    *   If queries are slow but not queued: Scale **Vertically**.
    *   If queries are waiting in a queue: Scale **Horizontally**.
4.  **Automation:** Implement auto-scaling policies to allow the system to expand during peak hours and contract during idle periods.

## Common Patterns
*   **Workload Isolation:** Assigning different warehouse sizes to different functional groups (e.g., a "Large" warehouse for Data Science/ML and a "Small" warehouse for Finance Reporting) to prevent resource contention.
*   **The "T-Shirt" Sizing Approach:** Using standardized, abstracted sizes (XS, S, M, L, XL) to simplify the management of compute resources across an organization.
*   **Scheduled Scaling:** Proactively increasing warehouse size in anticipation of known heavy loads, such as end-of-month financial closing or morning BI dashboard refreshes.

## Anti-Patterns
*   **The "One Size Fits All" Warehouse:** Using a single large warehouse for all company tasks, leading to high costs for simple queries and resource contention for complex ones.
*   **Over-Provisioning for Latency:** Scaling vertically to a massive size to shave seconds off a query that is not time-sensitive, resulting in diminishing returns and wasted expenditure.
*   **Ignoring Data Skew:** Attempting to solve performance issues with sizing when the underlying problem is uneven data distribution, which prevents effective parallelization regardless of cluster size.

> [!CAUTION]
> Avoid "Set and Forget" configurations. A warehouse sized for last year's data volume will likely become a bottleneck or a significant financial drain as data scales or query patterns evolve.

## Edge Cases
*   **Cold Start Latency:** The delay experienced when a warehouse is resumed from a suspended state. In high-concurrency, low-latency environments, the "warm-up" time must be factored into the performance SLA.
*   **Non-Parallelizable Operations:** Certain operations (e.g., specific UDFs or complex window functions with narrow partitions) cannot be distributed across multiple nodes. In these cases, increasing warehouse size provides zero performance gain.
*   **Metadata-Only Queries:** Queries that can be answered entirely by the service layer's metadata (e.g., `COUNT(*)` on some systems) do not require compute resources, making the warehouse size irrelevant.

## Related Topics
*   **Workload Management (WLM):** The prioritization of queries within a sized warehouse.
*   **Cost Governance:** The financial oversight of scaled compute resources.
*   **Data Modeling:** The structural design of data which dictates how effectively a warehouse can process it.

## Change Log
| Version | Date | Description |
|---------|------|-------------|
| 1.0 | 2026-01-26 | Initial AI-generated canonical documentation |