# 135. Azure Monitor Integration

Canonical documentation for [135. Azure Monitor Integration](Phase 6/135. Azure Monitor Integration.md). This document defines concepts, terminology, and standard usage.

## Purpose
The purpose of Azure Monitor Integration is to provide a unified observability framework for collecting, analyzing, and acting on telemetry from cloud and on-premises environments. It addresses the problem of fragmented data by consolidating disparate signals—such as performance metrics, activity logs, and application traces—into a centralized data platform. This integration enables organizations to maintain operational health, optimize resource utilization, and accelerate troubleshooting through automated insights and data-driven decision-making.

> [!NOTE]
> This documentation is intended to be implementation-agnostic and authoritative, focusing on the architectural principles of the integration rather than specific portal navigation.

## Scope
The scope of this documentation covers the architectural components and data flow logic required to interface external and internal systems with the Azure Monitor ecosystem.

> [!IMPORTANT]
> **In scope:**
> * Telemetry ingestion pipelines (Metrics, Logs, and Traces).
> * Diagnostic settings and resource-level instrumentation.
> * Data collection rules and agent-based telemetry gathering.
> * Theoretical boundaries of the Azure Monitor data platform.

> [!WARNING]
> **Out of scope:**
> * Specific third-party vendor software configurations (e.g., configuring a specific Grafana dashboard).
> * Step-by-step UI tutorials for the Azure Portal.
> * Pricing and billing tier comparisons.

## Definitions
| Term | Definition |
|------|------------|
| **Metrics** | Numerical values that describe some aspect of a system at a particular point in time, typically stored as time-series data. |
| **Logs** | Records of events that occurred within a system, often containing timestamped text or structured JSON data. |
| **Diagnostic Settings** | A configuration that defines which logs and metrics are exported from a resource and where they are sent. |
| **Log Analytics Workspace** | The logical storage unit and environment where log data is collected, aggregated, and analyzed. |
| **Kusto Query Language (KQL)** | The primary read-only request language used to process data and return results from the log store. |
| **Telemetry Agent** | A software component installed on a host (VM or on-premises) to collect guest-level performance and event data. |

## Core Concepts
Azure Monitor Integration is built upon the "Three Pillars of Observability": Metrics, Logs, and Traces. The integration architecture functions as a pipeline that transforms raw signals into actionable intelligence.

*   **Data Sources:** Integration begins at the source, which can range from the Azure platform itself (Tenant/Subscription level) to individual resources (Compute, Storage, Networking) and the applications running within them.
*   **The Data Platform:** At the center of the integration is a dual-backend system. One backend is optimized for time-series metrics (providing near real-time alerting), and the other is optimized for indexed logs (providing deep analytical capabilities).
*   **Insights and Visualization:** Once integrated, data is consumed by "Insights" (curated monitoring experiences) or custom visualizations.

> [!TIP]
> Think of Azure Monitor Integration as a central nervous system. The resources are the nerve endings (sensors), the integration pipelines are the nerves (transmission), and the Log Analytics Workspace is the brain (processing and memory).

## Standard Model
The standard model for Azure Monitor Integration follows a linear flow of telemetry:

1.  **Instrumentation/Collection:** Resources are configured to emit telemetry. This is achieved via Diagnostic Settings for platform services or via Agents (such as the Azure Monitor Agent) for operating systems.
2.  **Ingestion:** Data is transmitted via secure protocols (HTTPS/TLS) to the Azure Monitor ingestion service. During this phase, Data Collection Rules (DCRs) may be applied to filter or transform data before it reaches the store.
3.  **Storage:** Data is routed to either the Azure Monitor Metrics store or a Log Analytics Workspace.
4.  **Consumption:** The stored data is accessed via KQL queries, integrated into Workbooks, or used to trigger Alerts and Autoscale actions.

## Common Patterns
*   **The Hub-and-Spoke Logging Pattern:** Centralizing logs from multiple subscriptions into a single "Hub" Log Analytics Workspace for unified auditing and security analysis.
*   **Sidecar Pattern:** In containerized environments (like AKS), using a sidecar container to collect and forward application logs to Azure Monitor without modifying the application code.
*   **Streaming Integration:** Using Event Hubs as an intermediary to stream Azure Monitor data to external SIEM (Security Information and Event Management) or ITSM (IT Service Management) tools.
*   **Agent-based Hybrid Monitoring:** Deploying agents to on-premises servers to bridge the observability gap between local data centers and the cloud.

## Anti-Patterns
*   **The "Log Everything" Fallacy:** Collecting high-verbose debug logs in a production environment without a retention or filtering strategy, leading to excessive noise and storage costs.
*   **Siloed Workspaces:** Creating a separate Log Analytics Workspace for every individual resource, which prevents cross-resource correlation and complicates querying.
*   **Manual Log Parsing:** Relying on manual inspection of logs rather than defining structured schemas and automated alerts.
*   **Hard-coding Diagnostic Settings:** Failing to use Infrastructure as Code (IaC) to automate the integration of new resources into the monitoring framework.

> [!CAUTION]
> Avoid circular dependencies where the monitoring system depends on the very resources it is monitoring for its own operational availability.

## Edge Cases
*   **High-Cardinality Metrics:** When integrating custom application metrics, extremely high cardinality (e.g., unique IDs in metric dimensions) can lead to performance degradation or data rejection.
*   **Transient Connectivity:** Agents operating in "disconnected" or "intermittently connected" environments must be configured with local caching to prevent data loss during outages.
*   **Cross-Region Latency:** While Azure Monitor is global, sending logs across regions can introduce minor ingestion latency and potential data egress considerations.
*   **Multi-Tenant Isolation:** In service provider scenarios (Lighthouse), ensuring that telemetry integration respects tenant boundaries while allowing provider-level visibility requires complex RBAC and workspace design.

## Related Topics
*   **136. Log Analytics and KQL:** The primary method for querying integrated log data.
*   **137. Application Insights:** A sub-component of Azure Monitor specifically for Application Performance Management (APM).
*   **140. Azure Policy for Monitoring:** Using policy to enforce diagnostic settings across an enterprise.
*   **155. Managed Prometheus and Grafana:** Alternative integration paths for cloud-native metric monitoring.

## Change Log
| Version | Date | Description |
|---------|------|-------------|
| 1.0 | 2026-01-26 | Initial AI-generated canonical documentation |