# 119. Streaming Batch Unification

Canonical documentation for [119. Streaming Batch Unification](Phase 6/119. Streaming Batch Unification.md). This document defines concepts, terminology, and standard usage.

## Purpose
Streaming Batch Unification addresses the historical fragmentation between real-time data processing and historical bulk processing. Traditionally, organizations maintained two separate codebases, infrastructures, and logic sets: one for low-latency "streaming" data and another for high-throughput "batch" data. This fragmentation leads to "logic drift," where the results of a real-time calculation differ from the results of a batch recalculation.

The purpose of unification is to provide a single programming model and execution framework where batch processing is treated as a special case of stream processingâ€”specifically, a stream that has a defined beginning and end.

> [!NOTE]
> This documentation is intended to be implementation-agnostic and authoritative, focusing on the architectural convergence of data processing paradigms.

## Scope
Clarify what is in scope and out of scope for this topic.

> [!IMPORTANT]
> **In scope:**
> * The theoretical convergence of bounded and unbounded data processing.
> * Unified API design principles.
> * Consistency models across historical and real-time data.
> * Semantic equivalence in processing logic.

> [!WARNING]
> **Out of scope:**
> * Specific vendor implementations or proprietary cloud service benchmarks.
> * Hardware-level optimizations for specific storage formats (e.g., Parquet vs. Avro).
> * General database management system (DBMS) internals, unless related to stream-table duality.

## Definitions
| Term | Definition |
|------|------------|
| Bounded Data | A dataset with a defined start and end point (traditionally "Batch"). |
| Unbounded Data | A dataset that is continuously produced and has no defined end (traditionally "Stream"). |
| Event Time | The timestamp attached to a data point when the event actually occurred in the real world. |
| Processing Time | The time at which a data point is processed by the system. |
| Watermark | A progress metric in a stream that indicates no further events with earlier timestamps are expected. |
| Stream-Table Duality | The concept that a stream can be viewed as a changelog of a table, and a table can be viewed as a snapshot of a stream. |

## Core Concepts
The fundamental shift in Streaming Batch Unification is the move away from the "Lambda Architecture" (which maintains separate layers) toward a "Kappa Architecture" or a "Unified Model."

**Boundedness as a Subset**
In a unified model, all data is viewed as a stream. If the stream has a known end, it is "bounded." If it does not, it is "unbounded." By treating batch as a finite stream, the same operators (Map, Filter, Reduce, Join) can be applied to both without changing the underlying business logic.

**The Four Questions of Unified Processing**
To achieve unification, a system must answer four questions regardless of the data source:
1. **What** results are being computed? (Transformations)
2. **Where** in event time are results being computed? (Windowing)
3. **When** in processing time are results materialized? (Triggers)
4. **How** do refinements of results relate? (Accumulation)

> [!TIP]
> Think of a unified system like a video player. "Batch" is watching a recorded movie from start to finish (bounded), while "Streaming" is watching a live broadcast (unbounded). The "player" (the logic) remains the same; only the source of the data changes.

## Standard Model
The standard model for unification is built upon the **Dataflow Model**. This model decouples the logical pipeline from the physical execution environment.

1. **Unified API:** Developers write code once using a high-level API. The framework determines whether to optimize for high-throughput (batch) or low-latency (streaming) based on the data source.
2. **Event-Time Processing:** To ensure consistency between batch and stream, the system must process data based on when it happened, not when it was received. This allows "backfilling" (re-running historical data) to produce the exact same results as the original real-time run.
3. **State Management:** The system maintains "state" (e.g., running totals) consistently. In batch mode, state is often finalized at the end of the job. In streaming mode, state is periodically checkpointed to allow for recovery and incremental updates.

## Common Patterns
* **The Backfill Pattern:** Using the same unified pipeline to process three years of historical data (batch) to "warm up" a stateful operator before switching to live data (streaming).
* **Side Inputs:** Enriching a high-velocity stream with a large, slowly-changing dataset (batch) using a unified join operator.
* **Bootstrap Pattern:** Loading an initial version of a state store from a static file (batch) before beginning real-time processing.

## Anti-Patterns
* **Dual-Logic Maintenance:** Writing one SQL query for the data warehouse and a separate Java/Scala application for the streaming engine. This inevitably leads to inconsistent business metrics.
* **Processing-Time Dependency:** Relying on the system clock for logic. This makes batch-unification impossible because re-running historical data will yield different results based on the current time.
* **Manual State Synchronization:** Attempting to manually "stitch" batch results and stream results into a single view at the database layer rather than at the processing layer.

> [!CAUTION]
> Avoid circular dependencies where the output of a unified stream is required as a side-input for its own historical backfill without proper versioning or watermarking.

## Edge Cases
* **Late-Arriving Data:** In a unified model, data that arrives after a batch window has "closed" must be handled. A unified system uses "allowed lateness" parameters to decide whether to update the batch result or discard the data.
* **Schema Evolution:** Historical data (batch) may follow an older schema than live data (streaming). A unified pipeline must implement robust schema-on-read or transformation layers to bridge these differences.
* **Watermark Stalling:** In a unified join between a fast stream and a slow-moving batch source, the watermark may stall, preventing the system from emitting results.

## Related Topics
* **Event Sourcing:** The practice of capturing all changes to an application state as a sequence of events.
* **Change Data Capture (CDC):** A set of software design patterns used to determine and track the data that has changed.
* **Windowing Strategies:** Fixed, Sliding, and Session windows used to group data in unified processing.

## Change Log
| Version | Date | Description |
|---------|------|-------------|
| 1.0 | 2026-01-26 | Initial AI-generated canonical documentation |