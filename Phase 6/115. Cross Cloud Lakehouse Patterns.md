# 115. Cross Cloud Lakehouse Patterns

Canonical documentation for [115. Cross Cloud Lakehouse Patterns](Phase 6/115. Cross Cloud Lakehouse Patterns.md). This document defines concepts, terminology, and standard usage.

## Purpose
The Cross Cloud Lakehouse Pattern addresses the fragmentation of data assets across multiple cloud service providers (CSPs). As organizations adopt multi-cloud strategies—whether through intentional diversification, mergers and acquisitions, or regional availability requirements—they face the challenge of maintaining a unified data architecture. 

This topic exists to provide a framework for combining the performance and governance of a data warehouse with the scale and flexibility of a data lake across disparate cloud environments. It aims to solve problems related to data silos, high egress costs, inconsistent governance, and the "data gravity" problem that occurs when compute resources are separated from the storage layer by cloud boundaries.

> [!NOTE]
> This documentation is intended to be implementation-agnostic and authoritative, focusing on architectural integrity rather than specific vendor tooling.

## Scope
Clarify what is in scope and out of scope for this topic.

> [!IMPORTANT]
> **In scope:**
> * Architectural strategies for data consistency across cloud boundaries.
> * Metadata synchronization and global cataloging.
> * Strategies for minimizing data movement and egress overhead.
> * Unified security and governance models in multi-cloud environments.
> * Open table formats as the foundation for interoperability.

> [!WARNING]
> **Out of scope:**
> * Specific vendor implementations (e.g., specific configurations for Databricks, Snowflake, or BigQuery).
> * General multi-cloud networking (VPNs, Direct Connect) unless specifically related to data transfer.
> * Traditional on-premises to cloud migrations (Hybrid Cloud).

## Definitions
| Term | Definition |
|------|------------|
| Lakehouse | A data management system that implements data warehouse-like features (ACID transactions, schema enforcement) on top of low-cost cloud object storage. |
| Data Gravity | The concept that as data sets grow, they attract applications and compute power, making them difficult and expensive to move. |
| Egress | Data leaving a cloud provider's network, typically incurring significant financial costs. |
| Open Table Format | A specification (e.g., Delta Lake, Apache Iceberg, Apache Hudi) that allows multiple engines to interact with data in object storage with transactional integrity. |
| Global Metadata Catalog | A centralized or federated service that tracks the location, schema, and permissions of data across all cloud environments. |
| Zero-Copy Sharing | A method of providing access to data across accounts or clouds without physically moving or duplicating the underlying files. |

## Core Concepts
The Cross Cloud Lakehouse relies on the fundamental decoupling of storage, compute, and metadata.

1.  **Storage Abstraction:** Data resides in native cloud object storage (S3, ADLS, GCS) using open formats. This ensures that the data is not locked into a specific vendor's proprietary format.
2.  **Compute Locality:** To minimize latency and egress costs, compute tasks should be executed in the same cloud region where the data resides.
3.  **Unified Governance:** A single policy layer must dictate who can access what data, regardless of which cloud the user is logged into or where the data is stored.
4.  **Metadata Federation:** Since a single physical catalog across clouds is often impractical due to latency, a federated approach or a high-speed synchronization mechanism is required to maintain a "single source of truth" for data definitions.

> [!TIP]
> Think of a Cross Cloud Lakehouse like a global library system. The books (data) stay in their local branches (clouds) to save on shipping costs, but there is a single digital card catalog (metadata) that tells you exactly where every book is and allows you to request a summary (query result) without moving the whole book.

## Standard Model
The standard model for a Cross Cloud Lakehouse is the **Federated Governance Model**. In this model:

*   **Primary Hub:** One cloud acts as the primary governance and metadata hub.
*   **Satellite Spokes:** Other clouds act as execution environments.
*   **Open Standards:** All data is stored in an Open Table Format to ensure that compute engines in Cloud A can read data written by Cloud B.
*   **Policy Orchestration:** Security policies are authored once in the Hub and pushed to or pulled by the Spokes to ensure consistent enforcement.

## Common Patterns

### 1. The "Single Pane of Glass" (Federated Query)
Compute engines in a primary cloud query data residing in secondary clouds in real-time. 
*   **Use Case:** Low-volume data access or joining small remote tables with large local tables.
*   **Trade-off:** High latency and potential egress costs for large scans.

### 2. Bi-Directional Replication
Critical datasets are synchronized across clouds.
*   **Use Case:** Disaster recovery and high-performance local access for global teams.
*   **Trade-off:** Increased storage costs and complexity in maintaining consistency (eventual consistency).

### 3. The "Medallion" Multi-Cloud Pipeline
Raw data (Bronze) is ingested in Cloud A, cleaned (Silver) in Cloud B, and aggregated (Gold) in Cloud C based on where specific toolsets or business units reside.
*   **Use Case:** Leveraging specific cloud-native AI/ML services that only exist in one provider.

### 4. Data Mesh (Cross-Cloud)
Different domains own their data in their preferred cloud, but expose standardized "Data Products" via a global catalog.

## Anti-Patterns

*   **The Egress Blind Spot:** Moving massive raw datasets between clouds for every query instead of filtering/aggregating at the source.
*   **Proprietary Lock-in at the Storage Layer:** Using vendor-specific storage formats that cannot be read by other cloud engines without a translation layer.
*   **Siloed Identity Management:** Maintaining separate user lists and permissions in every cloud, leading to security gaps and "privilege creep."
*   **Manual Metadata Sync:** Relying on human intervention to update schemas across clouds, which inevitably leads to schema drift.

> [!CAUTION]
> Avoid circular dependencies where Cloud A's processing requires Cloud B's data, which in turn requires a lookup from Cloud A. This creates "chatter" that exponentially increases costs and latency.

## Edge Cases

*   **Sovereign Clouds:** Data in certain jurisdictions (e.g., specific EU regions or government clouds) may be legally prohibited from being replicated or even metadata-synced to other clouds.
*   **Air-Gapped Environments:** High-security environments that require physical or logical isolation, making real-time cross-cloud patterns impossible.
*   **Transient Clouds:** Using a second cloud only for "burst" compute during peak periods, requiring rapid, temporary data hydration.

## Related Topics
*   **102. Open Table Formats:** The underlying technology (Iceberg, Delta) that makes cross-cloud interoperability possible.
*   **205. Data Governance Frameworks:** The methodology for managing data access and quality.
*   **310. FinOps for Data Engineering:** Managing the costs associated with egress and multi-cloud storage.

## Change Log
| Version | Date | Description |
|---------|------|-------------|
| 1.0 | 2026-01-26 | Initial AI-generated canonical documentation |