# 112. Multi Catalog Data Product Organization

Canonical documentation for [112. Multi Catalog Data Product Organization](Phase 6/112. Multi Catalog Data Product Organization.md). This document defines concepts, terminology, and standard usage.

## Purpose
The purpose of Multi Catalog Data Product Organization is to provide a structured framework for managing, discovering, and governing data products that reside across disparate metadata repositories or geographic regions. In modern decentralized architectures—such as Data Mesh or multi-cloud environments—a single, monolithic catalog often fails to meet the specialized needs of individual business units while maintaining enterprise-wide visibility.

This topic addresses the challenge of maintaining a "single pane of glass" for data consumers while allowing data producers the autonomy to use tools and taxonomies optimized for their specific domains. It ensures that data products remain findable, accessible, interoperable, and reusable (FAIR) regardless of their underlying storage or primary cataloging system.

> [!NOTE]
> This documentation is intended to be implementation-agnostic and authoritative, focusing on the logical architecture of metadata rather than specific software features.

## Scope
The scope of this document covers the organizational logic, metadata synchronization strategies, and governance models required to link multiple data catalogs into a cohesive ecosystem.

> [!IMPORTANT]
> **In scope:**
> * Logical architecture of federated and hierarchical catalog systems.
> * Metadata mapping and standardization across catalog boundaries.
> * Discovery mechanisms for cross-domain data products.
> * Governance frameworks for multi-catalog environments.

> [!WARNING]
> **Out of scope:**
> * Specific vendor implementations or software comparisons.
> * Physical data movement or ETL/ELT processes (this focuses on the metadata layer).
> * General database management unrelated to product-centric organization.

## Definitions
| Term | Definition |
|------|------------|
| Data Product | A logical unit containing data, metadata, and the necessary code/infrastructure to serve a specific business purpose to consumers. |
| Local Catalog | A metadata repository managed by a specific domain or business unit, containing granular details relevant to that domain. |
| Global Catalog | A centralized or federated discovery layer that aggregates high-level metadata from multiple local catalogs for enterprise-wide search. |
| Federated Discovery | The ability to query multiple independent catalogs simultaneously to find data products without moving the metadata to a central store. |
| Metadata Mapping | The process of aligning different schemas, tags, and taxonomies from various catalogs to a common enterprise standard. |
| Domain | A functional area of an organization (e.g., Finance, Marketing) that owns and manages its own data products and local catalog. |

## Core Concepts
The organization of data products across multiple catalogs relies on the balance between **Domain Autonomy** and **Global Interoperability**.

### The Metadata Hierarchy
Data products exist in a hierarchy where technical metadata (schemas, partitions) often resides in a local catalog, while business metadata (ownership, SLAs, quality scores) is promoted to a global layer. This prevents the global catalog from becoming cluttered with low-level operational noise.

### Federated Governance
Governance in a multi-catalog environment is not top-down but federated. Global policies (e.g., "All data products must have a PII tag") are defined centrally but enforced locally within each catalog.

> [!TIP]
> Think of multi-catalog organization like a library system: individual branches (Local Catalogs) manage their own shelves and local events, but a central digital search portal (Global Catalog) allows a patron to find a book regardless of which branch holds it.

## Standard Model
The standard model for Multi Catalog Data Product Organization typically follows a **Hub-and-Spoke** or **Federated Mesh** architecture.

1.  **The Local Layer (Spokes):** Each domain maintains its own catalog. This catalog contains the "Source of Truth" for the data product's technical implementation.
2.  **The Integration Layer:** A set of connectors or listeners that monitor local catalogs for changes to "Public" data products.
3.  **The Global Layer (Hub):** A curated repository that stores only the metadata necessary for discovery and governance. This includes:
    *   Product Name and Description.
    *   Ownership and Contact Information.
    *   Access Request Workflows.
    *   Data Quality Indicators.
    *   Links/Pointers back to the Local Catalog for technical details.

## Common Patterns

### 1. Metadata Harvesting (Push/Pull)
Local catalogs periodically "push" metadata updates to a central registry, or a central service "pulls" updates via APIs. This creates a physical copy of metadata in a central location.

### 2. Virtualized Federation
The global catalog does not store metadata but acts as a query engine. When a user searches for a data product, the global catalog queries all connected local catalogs in real-time and aggregates the results.

### 3. The "Marketplace" Pattern
The organization treats the global catalog as a storefront. Data products are "published" to the marketplace only when they reach a certain maturity level (e.g., certified quality, documented schema), regardless of which local catalog they originated from.

## Anti-Patterns

### The Metadata Monolith
Attempting to force every business unit into a single, rigid catalog instance. This leads to "lowest common denominator" metadata where specialized domain needs are ignored, eventually causing domains to create "Shadow Catalogs."

### The "Sync-All" Strategy
Synchronizing every piece of technical metadata (e.g., every temporary table or internal staging file) to the global catalog. This creates significant noise and makes it impossible for consumers to find actual data products.

> [!CAUTION]
> Avoid tight coupling between the Global Catalog and Local Catalog schemas. If the Global Catalog requires a specific local schema to function, a single change in a local domain can break the entire enterprise discovery layer.

## Edge Cases

### Mergers and Acquisitions (M&A)
When two companies merge, they often have incompatible cataloging technologies. Multi-catalog organization allows the parent company to create a federated discovery layer without forcing an immediate, high-risk migration of the acquired company's metadata.

### Regulatory Silos
In some jurisdictions, metadata itself may be subject to data residency laws. In these cases, a global catalog may only show the *existence* of a data product, while the actual metadata details remain locked within a local catalog in a specific region.

### Transient Data Products
Short-lived data products created for specific data science experiments. These are often kept in local catalogs and never promoted to the global layer to avoid polluting the enterprise search space.

## Related Topics
*   **Data Mesh Architecture:** The organizational philosophy that often necessitates multi-catalog strategies.
*   **Data Contract Management:** The technical agreements that define the metadata shared between catalogs.
*   **Federated Identity Management:** Necessary for ensuring that a user discovered in a global catalog has the same permissions when redirected to a local catalog.
*   **Metadata Standards (e.g., DCAT, OCF):** Standardized formats for exchanging metadata between different catalog vendors.

## Change Log
| Version | Date | Description |
|---------|------|-------------|
| 1.0 | 2026-01-26 | Initial AI-generated canonical documentation |