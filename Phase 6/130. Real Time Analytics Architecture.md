# 130. Real Time Analytics Architecture

Canonical documentation for [130. Real Time Analytics Architecture](Phase 6/130. Real Time Analytics Architecture.md). This document defines concepts, terminology, and standard usage.

## Purpose
Real Time Analytics Architecture exists to enable the processing and analysis of data as it is generated, minimizing the "time-to-insight." Traditional analytics often rely on batch processing (e.g., T+1 reporting), which introduces significant latency. This architecture addresses the need for immediate operational intelligence, fraud detection, dynamic pricing, and proactive system monitoring where the value of data diminishes rapidly over time.

> [!NOTE]
> This documentation is intended to be implementation-agnostic and authoritative, focusing on the structural requirements of low-latency data pipelines.

## Scope
Clarify what is in scope and out of scope for this topic.

> [!IMPORTANT]
> **In scope:**
> * Data ingestion strategies for continuous streams.
> * Stream processing paradigms (stateful vs. stateless).
> * Low-latency storage and serving layers.
> * Time semantics and windowing logic.

> [!WARNING]
> **Out of scope:**
> * Specific vendor implementations (e.g., specific cloud provider services).
> * Hardware-level optimizations.
> * General Business Intelligence (BI) visualization techniques not specific to real-time data.

## Definitions
Provide precise definitions for key terms.

| Term | Definition |
|------|------------|
| Event | A discrete, immutable record representing a state change or occurrence at a specific point in time. |
| Stream | An unbounded sequence of events ordered by time. |
| Latency | The time elapsed between the occurrence of an event and the availability of its processed insight. |
| Throughput | The volume of events processed by the architecture within a given time unit. |
| Windowing | The process of grouping events into temporal or numerical buckets for aggregate analysis. |
| State | The stored information representing the "memory" of a stream processor, used to correlate events over time. |
| Watermark | A threshold used to track progress in event time and handle late-arriving data. |

## Core Concepts
Explain the fundamental ideas.

### Event-Driven Nature
Real-time architectures are fundamentally reactive. Instead of requesting data (pull), the system responds to data as it arrives (push). This requires an immutable log of events that serves as the "source of truth."

### Time Semantics
Distinguishing between different types of time is critical for accuracy:
*   **Event Time:** When the event actually occurred on the source device.
*   **Ingestion Time:** When the event entered the processing system.
*   **Processing Time:** When the system actually executed the logic on the event.

> [!TIP]
> Think of a postmark on an envelope. The "Event Time" is the date written on the letter, the "Ingestion Time" is the postmark from the post office, and the "Processing Time" is when you actually read the letter. Real-time systems must prioritize Event Time to ensure correctness despite network delays.

### Stream-Table Duality
A stream can be viewed as a table (a changelog), and a table can be viewed as a stream (a snapshot of the latest state). Real-time architecture often involves converting streams into materialized views (tables) for fast querying.

## Standard Model
The generally accepted model for real-time analytics is the **Kappa Architecture**, which has largely superseded the older **Lambda Architecture** in modern implementations.

1.  **Ingestion Layer:** Decouples data producers from consumers using a distributed message bus or commit log.
2.  **Stream Processing Layer:** Consumes events, performs transformations, enrichments, and aggregations. This layer maintains "state" for complex calculations (e.g., moving averages).
3.  **Serving Layer:** Stores the processed results in a format optimized for low-latency queries (e.g., OLAP cubes, NoSQL stores, or In-Memory databases).
4.  **Consumer Layer:** Applications or dashboards that query the serving layer or subscribe to processed output streams.

## Common Patterns
*   **Change Data Capture (CDC):** Monitoring database logs to stream row-level changes into the analytics pipeline in real-time.
*   **Event Sourcing:** Storing every change to application state as a sequence of events, allowing the state to be reconstructed at any point.
*   **Fan-out:** Sending a single incoming event to multiple specialized processing pipelines or storage sinks simultaneously.
*   **Enrichment:** Joining a real-time stream with static or slowly-changing reference data (e.g., adding customer names to a stream of transaction IDs).

## Anti-Patterns
*   **Database-as-a-Queue:** Using a traditional relational database to store temporary event data for processing, leading to high contention and locking issues.
*   **Polling for Changes:** Periodically querying a source system for new data instead of using a push-based mechanism, which introduces artificial latency.
*   **Monolithic Processing:** Building a single, massive processing logic that is difficult to scale or update without stopping the entire stream.
*   **Ignoring Out-of-Order Data:** Assuming events will arrive in the exact order they occurred, leading to inaccurate aggregations.

> [!CAUTION]
> Avoid tight coupling between the ingestion layer and the processing logic. If the processor cannot keep up with the ingestion rate, the system must support "backpressure" to prevent catastrophic memory failure.

## Edge Cases
*   **Late-Arriving Data:** Events that arrive after the system has already closed a time window. This requires "grace periods" or "side-output" streams for late corrections.
*   **Network Partitions:** When a segment of the architecture becomes unreachable, the system must decide between consistency (waiting for the data) and availability (continuing with partial data).
*   **Schema Evolution:** Handling changes in the structure of events (e.g., adding or removing fields) without breaking downstream processors.
*   **Clock Skew:** Significant differences between the clocks of various event producers, which can distort event-time processing.

## Related Topics
*   **110. Batch Processing Systems:** The historical counterpart to real-time analytics.
*   **140. Event-Driven Microservices:** Architectural patterns that often produce the data consumed by real-time analytics.
*   **150. Distributed Systems Consistency Models:** Theoretical foundations for how data is synchronized across real-time nodes.
*   **OLAP (Online Analytical Processing):** The category of storage often used in the serving layer.

## Change Log
| Version | Date | Description |
|---------|------|-------------|
| 1.0 | 2026-01-26 | Initial AI-generated canonical documentation |